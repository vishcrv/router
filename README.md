# LLM Router API â€“ Smart Model Selection for LLMs

by vishnu and ivan

## ğŸ” Overview

This API dynamically selects and routes a user's prompt to the best-suited LLM from a pool of 5 models:

- DeepSeek R1
- Mistral Small
- Qwen2.5
- Gemini Flash
- Llama 3.3

Unlike static rule-based routing, this system uses a fine-tuned classifier (DistilBERT) to select the most appropriate model for a given prompt.

## ğŸ§  Core Logic

- **Model Selection**: `llm_selector.py` uses a trained transformer classifier to predict the best LLM.
- **Model Querying**: `router.py` sends requests to OpenRouter-backed APIs.
- **Response Evaluation**: `evaluator.py` compares all model responses and scores them for benchmarking.

## ğŸ“ File Structure

```bash
â”œâ”€â”€ app.py                     # FastAPI entrypoint (formerly main.py)
â”œâ”€â”€ llm_selector.py           # Classifier-based model selection
â”œâ”€â”€ router.py                 # Model querying + health checks
â”œâ”€â”€ evaluator.py              # Multi-dimensional response scoring
â”œâ”€â”€ llms.py                   # API config for each model
â”œâ”€â”€ selector_model/           # Trained DistilBERT classifier
â”œâ”€â”€ label_encoder.json        # Model-to-class label mapping
â”œâ”€â”€ *.json                    # Sample prompts & datasets
```

## ğŸš€ Running Locally

- Prerequisites:

```bash
pip install -r requirements.txt
```

- Run the API:

```bash
export OPENROUTER_API_KEY=your-api-key
python app.py
```

##ğŸ”Œ Endpoints

`POST /query`

- Selects the best model via classifier and routes the prompt.

- Request:

```bash
{ "prompt": "Write a Python function to calculate factorial" }
```

-Response

```bash
{
  "prompt": "...",
  "selected_model": "llama-3.3",
  "response": "...",
  "selection_confidence": 0.93,
  "reasoning": "Predicted 'llama-3.3' with confidence 0.93"
}
```

`POST /query-compare`

- Compares classifier-selected model to all models and evaluates correctness.

```bash
curl -X POST http://localhost:8000/query-compare \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Explain the benefits of renewable energy"}'
```

```bash
curl -X POST http://localhost:8000/query-specific \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What is the capital of India?", "model": "gemini-flash"}'
```

`POST /batch-query`

- Handles multiple prompts and optionally enables comparison

`POST /test-selection`

- Returns classifier decisions across sample prompts.

## ğŸ“Š Evaluator Scoring

| Dimension                  | Max Points |
| -------------------------- | ---------- |
| Structure                  | 2          |
| Examples                   | 1.5        |
| Formatting                 | 1          |
| Code Quality               | 4          |
| Math Accuracy              | 4          |
| Creativity                 | 4          |
| Factual Content            | 3          |
| Visual Descrip.            | 3          |
| Repetition/Error Penalties | -14        |

## ğŸ›  Classifier Info

- Model: DistilBERT (Fine-tuned)
- Input: Natural language prompt
- Output: Predicted best model label
- Confidence: Softmax class probability

## ğŸ§  Future Plans

- Add few-shot prompting support
- Live feedback loop for continual learning
- Model latency & cost-based routing
